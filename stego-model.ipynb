{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102},{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":28484,"sourceType":"modelInstanceVersion","modelInstanceId":23989,"modelId":34549}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision matplotlib\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:01:29.167297Z","iopub.execute_input":"2025-01-08T16:01:29.167643Z","iopub.status.idle":"2025-01-08T16:01:32.429273Z","shell.execute_reply.started":"2025-01-08T16:01:29.167614Z","shell.execute_reply":"2025-01-08T16:01:32.428286Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# === Configuration and Imports ===\nimport torch\nfrom torch.utils.data import DataLoader, random_split, ConcatDataset\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torchvision import datasets, transforms\nfrom torchvision.models import resnet18, ResNet18_Weights\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import random_split, DataLoader\n\n# Configuration\nBATCH_SIZE = 64\nLEARNING_RATE = 0.001\nEPOCHS = 5\nCOCO_CLASSES = 80  # Adjust based on the specific COCO task\n\n# Check for GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T17:18:04.097104Z","iopub.execute_input":"2025-01-08T17:18:04.097503Z","iopub.status.idle":"2025-01-08T17:18:04.104242Z","shell.execute_reply.started":"2025-01-08T17:18:04.097470Z","shell.execute_reply":"2025-01-08T17:18:04.103282Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"# === Data Augmentation and Normalization ===\ntransform_coco = transforms.Compose([\n    transforms.Resize((128, 128)),  # Resize all images to 128x128\n    transforms.RandomHorizontalFlip(),  # Data Augmentation: Random Horizontal Flip\n    transforms.ToTensor(),  # Convert images to tensor format\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize image data\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:01:32.440402Z","iopub.execute_input":"2025-01-08T16:01:32.440799Z","iopub.status.idle":"2025-01-08T16:01:32.452186Z","shell.execute_reply.started":"2025-01-08T16:01:32.440761Z","shell.execute_reply":"2025-01-08T16:01:32.451346Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader, ConcatDataset\nfrom torchvision import datasets, transforms\nimport torch\n\n# Define data transformations with 128x128 resize\ntransform_train = transforms.Compose([\n    transforms.Resize(256),  # Resize the image while maintaining the aspect ratio\n    transforms.RandomResizedCrop(128),  # Random crop to 128x128\n    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(256),  # Resize the image while maintaining the aspect ratio\n    transforms.CenterCrop(128),  # Crop the image to 128x128 from the center\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n])\n\n# Custom collate_fn to handle both CIFAR-10 and COCO datasets\ndef custom_collate_fn(batch):\n    images = [item[0] for item in batch]\n    \n    # If the item is from CIFAR-10, labels are integers (class labels)\n    if isinstance(batch[0][1], int):  # CIFAR-10\n        labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n    else:  # COCO\n        # Extract the category IDs from the annotations (assumed to be in item[1])\n        # COCO annotations are a list of dictionaries, each containing 'category_id'\n        labels = torch.tensor([item[1][0]['category_id'] for item in batch], dtype=torch.long)  # Extracting category ID\n    \n    images = torch.stack(images, dim=0)  # Stack images into a tensor\n    return images, labels\n\n# === Load CIFAR-10 Dataset ===\ntrain_data_cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_data_cifar = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\n# === Load COCO Dataset ===\ntrain_data_coco = datasets.CocoDetection(\n    root='/kaggle/input/coco-2017-dataset/coco2017/train2017',  # Path to training images\n    annFile='/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_train2017.json',  # Path to training annotations\n    transform=transform_train\n)\n\ntest_data_coco = datasets.CocoDetection(\n    root='/kaggle/input/coco-2017-dataset/coco2017/val2017',  # Path to validation images\n    annFile='/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json',  # Path to validation annotations\n    transform=transform_test\n)\n\n# === Combine Datasets ===\ntrain_data_combined = ConcatDataset([train_data_cifar, train_data_coco])  # Combine CIFAR-10 and COCO training data\ntest_data_combined = ConcatDataset([test_data_cifar, test_data_coco])    # Combine CIFAR-10 and COCO testing data\n\n# === Split the Combined Dataset ===\ntrain_size = int(0.7 * len(train_data_combined))  # 70% for training\ntest_size = len(train_data_combined) - train_size  # 30% for testing\n\ntrain_dataset, test_dataset = random_split(train_data_combined, [train_size, test_size])\n\n# === Create DataLoaders ===\nBATCH_SIZE = 64  # Example batch size\n\n# DataLoader with custom collate_fn to handle mixed formats (CIFAR-10 and COCO)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n\n# Confirm the transformation is applied correctly\nfor images, labels in train_loader:\n    print(images.shape)  # Should print [BATCH_SIZE, 3, 128, 128]\n    print(type(labels))  # Should print <class 'torch.Tensor'>\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T17:25:38.195010Z","iopub.execute_input":"2025-01-08T17:25:38.195383Z","iopub.status.idle":"2025-01-08T17:26:00.518093Z","shell.execute_reply.started":"2025-01-08T17:25:38.195341Z","shell.execute_reply":"2025-01-08T17:26:00.516874Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nloading annotations into memory...\nDone (t=18.67s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.50s)\ncreating index...\nindex created!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-9a336d196975>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Confirm the transformation is applied correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should print [BATCH_SIZE, 3, 128, 128]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should print <class 'torch.Tensor'>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-78-9a336d196975>\u001b[0m in \u001b[0;36mcustom_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Extract the category IDs from the annotations (assumed to be in item[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# COCO annotations are a list of dictionaries, each containing 'category_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Extracting category ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stack images into a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-9a336d196975>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Extract the category IDs from the annotations (assumed to be in item[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# COCO annotations are a list of dictionaries, each containing 'category_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Extracting category ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stack images into a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"],"ename":"TypeError","evalue":"'int' object is not subscriptable","output_type":"error"}],"execution_count":78},{"cell_type":"code","source":"# === Model Definition ===\n# Load ResNet-18 pre-trained on ImageNet\nmodel = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n\n# Modify the final layer to fit the combined task\nmodel.fc = nn.Linear(model.fc.in_features, 10)  # Change 10 to your specific number of output classes\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:46:57.035058Z","iopub.execute_input":"2025-01-08T16:46:57.035511Z","iopub.status.idle":"2025-01-08T16:46:57.298845Z","shell.execute_reply.started":"2025-01-08T16:46:57.035470Z","shell.execute_reply":"2025-01-08T16:46:57.297846Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# === Define Model, Loss Function, and Optimizer ===\n# Assuming 'model' is already defined\ncriterion = torch.nn.CrossEntropyLoss()  # Example loss function\nLEARNING_RATE = 0.001  # Set a learning rate\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Define optimizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:01:55.133942Z","iopub.execute_input":"2025-01-08T16:01:55.134222Z","iopub.status.idle":"2025-01-08T16:01:55.138515Z","shell.execute_reply.started":"2025-01-08T16:01:55.134190Z","shell.execute_reply":"2025-01-08T16:01:55.137614Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#### === Training Loop ===\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    for images, annotations in train_loader:\n        # Move images to the device\n        images = images.to(device)\n        \n        # Generate predictions\n        outputs = model(images)\n        \n        # Generate dummy labels (if not using annotations directly)\n        labels = torch.zeros(len(images), dtype=torch.long).to(device)  # Adjust as needed\n        \n        # Compute loss\n        loss = criterion(outputs, labels)\n        \n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {running_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-01-08T16:01:55.140928Z","iopub.execute_input":"2025-01-08T16:01:55.141154Z","iopub.status.idle":"2025-01-08T16:28:28.416592Z","shell.execute_reply.started":"2025-01-08T16:01:55.141136Z","shell.execute_reply":"2025-01-08T16:28:28.414052Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/5, Loss: 9.2467\nEpoch 2/5, Loss: 0.0067\nEpoch 3/5, Loss: 0.0014\nEpoch 4/5, Loss: 0.0003\nEpoch 5/5, Loss: 0.0000\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# === Loss Function and Optimizer ===\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# === Training Function ===\ndef train_model(model, loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    return running_loss / len(loader)\n\n# === Evaluation Function ===\ndef evaluate_model(model, loader, device):\n    model.eval()  # Set the model to evaluation mode\n    \n    correct = 0\n    total = 0\n    \n    # Ensure the data loader is not empty\n    if len(loader.dataset) == 0:\n        print(\"The test loader is empty!\")\n        return 0\n    \n    with torch.no_grad():\n        for images, annotations in loader:\n            images = images.to(device)  # Move images to the device\n            labels = annotations  # Extract labels (in COCO annotations, they could be complex)\n            \n            # If annotations are a list of dictionaries, extract 'category_id'\n            if isinstance(labels, list):\n                labels = [ann['category_id'] for ann in labels if isinstance(ann, dict)]\n            \n            # If labels are in a simple format (int or tensor), handle it correctly\n            if isinstance(labels, int):\n                labels = [labels]  # Convert to a list\n            \n            if len(labels) == 0:  # Check if labels are empty\n                print(f\"Warning: Empty labels found in this batch\")\n                continue  # Skip this batch\n\n            labels = torch.tensor(labels).to(device)  # Convert to tensor and move to device\n            \n            # Forward pass\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            \n            # Check the shapes to debug\n            print(f\"Predicted shape: {predicted.shape}, Labels shape: {labels.shape}\")\n            \n            # Count correct predictions\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    # Avoid division by zero\n    if total == 0:\n        print(\"No data found in the test loader!\")\n        return 0\n    \n    accuracy = (100 * correct / total)\n    return accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T17:05:21.047428Z","iopub.execute_input":"2025-01-08T17:05:21.047782Z","iopub.status.idle":"2025-01-08T17:05:21.057583Z","shell.execute_reply.started":"2025-01-08T17:05:21.047757Z","shell.execute_reply":"2025-01-08T17:05:21.056371Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"# Load the model\nmodel = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\nmodel.fc = nn.Linear(model.fc.in_features, 10)  # Adjust the number of output classes\nmodel.load_state_dict(torch.load('stegonet.pth'))\nmodel.to(device)\n\n# Evaluate the model to confirm it works as expected\naccuracy = evaluate_model(model, test_loader, device)\nprint(f\"Accuracy of the loaded model: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T17:05:26.161740Z","iopub.execute_input":"2025-01-08T17:05:26.162051Z","iopub.status.idle":"2025-01-08T17:05:48.031790Z","shell.execute_reply.started":"2025-01-08T17:05:26.162030Z","shell.execute_reply":"2025-01-08T17:05:48.030701Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-69-98b524cf2a39>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('stegonet.pth'))\n","output_type":"stream"},{"name":"stdout","text":"Warning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nWarning: Empty labels found in this batch\nNo data found in the test loader!\nAccuracy of the loaded model: 0.00%\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), 'stegonet.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T16:28:28.430133Z","iopub.execute_input":"2025-01-08T16:28:28.430467Z","iopub.status.idle":"2025-01-08T16:28:28.592181Z","shell.execute_reply.started":"2025-01-08T16:28:28.430429Z","shell.execute_reply":"2025-01-08T16:28:28.591481Z"}},"outputs":[],"execution_count":42}]}