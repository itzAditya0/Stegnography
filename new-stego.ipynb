{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102},{"sourceId":502445,"sourceType":"datasetVersion","datasetId":236239},{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":2307647,"sourceType":"datasetVersion","datasetId":1391879},{"sourceId":4043617,"sourceType":"datasetVersion","datasetId":2395063},{"sourceId":5030375,"sourceType":"datasetVersion","datasetId":2919327}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet-pytorch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:22:36.401356Z","iopub.execute_input":"2025-01-12T12:22:36.401687Z","iopub.status.idle":"2025-01-12T12:22:45.145083Z","shell.execute_reply.started":"2025-01-12T12:22:36.401661Z","shell.execute_reply":"2025-01-12T12:22:45.144267Z"}},"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch) (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=1142affeb526346f85df7bb72cf3b4a576a4a2248350a118ca7fba8aafadbd17\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, ConcatDataset\nfrom torchvision import datasets, transforms, models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom efficientnet_pytorch import EfficientNet\nimport numpy as np\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets import FashionMNIST","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:22:54.207506Z","iopub.execute_input":"2025-01-12T12:22:54.208085Z","iopub.status.idle":"2025-01-12T12:22:54.213123Z","shell.execute_reply.started":"2025-01-12T12:22:54.208052Z","shell.execute_reply":"2025-01-12T12:22:54.212140Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define Transformation\n\ndef get_transform():\n    return transforms.Compose([\n        transforms.Resize((128, 128)),  # Resize all images to 128x128\n        transforms.Grayscale(num_output_channels=3),  # Convert grayscale images to 3 channels\n        transforms.ToTensor(),  # Convert images to tensor\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images for 3 channels\n    ])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example for FashionMNIST dataset\nfrom torchvision.datasets import FashionMNIST\n\nfashion_mnist_train = FashionMNIST(root='data', train=True, download=True, transform=get_transform())\nfashion_mnist_test = FashionMNIST(root='data', train=False, download=True, transform=get_transform())\n\n# You can apply similar code to the other datasets.\n\ntransform = get_transform()\n\n# Load CIFAR-10 dataset\ncifar10_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ncifar10_test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n# Load FashionMNIST dataset\nfashionmnist_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\nfashionmnist_test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# Load StegoImages dataset\nfrom torchvision.datasets import ImageFolder\nstego_data = ImageFolder(root='/kaggle/input/stegoimagesdataset/train', transform=transform)\nstego_test_data = ImageFolder(root='/kaggle/input/stegoimagesdataset/test', transform=transform)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_train_data = ConcatDataset([cifar10_data, fashionmnist_data, stego_data])\ncombined_test_data = ConcatDataset([cifar10_test_data, fashionmnist_test_data, stego_test_data])\n\ntrain_loader = DataLoader(combined_train_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(combined_test_data, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StegoLocationNet(nn.Module):\n    def __init__(self, num_classes):\n        super(StegoLocationNet, self).__init__()\n        self.num_classes = num_classes\n\n        # Load EfficientNet base model\n        self.base_model = EfficientNet.from_pretrained('efficientnet-b0')\n\n        # Retrieve the in_features from the original _fc layer\n        if hasattr(self.base_model, '_fc') and isinstance(self.base_model._fc, nn.Linear):\n            in_features = self.base_model._fc.in_features\n        else:\n            raise AttributeError(\"EfficientNet model does not have a valid '_fc' layer.\")\n\n        # Replace the classification layer\n        self.base_model._fc = nn.Identity()  # Remove the existing fully connected layer\n\n        # Add custom classification head\n        self.classifier = nn.Linear(in_features, num_classes)\n\n        # Add location detection layers\n        self.location_head = nn.Sequential(\n            nn.Conv2d(in_features, 128, kernel_size=1),  # Match input channels to 1280\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 1, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Extract features before the final classifier\n        features = self.base_model.extract_features(x)\n\n        # Generate location map\n        location_map = self.location_head(features)\n\n        # Optional classification (not used for location-only tasks)\n        pooled_features = torch.mean(features, dim=[2, 3])  # Global average pooling\n        class_output = self.classifier(pooled_features)\n\n        return location_map, class_output\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_hiding_spots(images):\n    # Example heuristic: higher values in uniform regions\n    # Apply Sobel filter to find edges\n    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).view(1, 1, 3, 3).float().to(images.device)\n    sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]).view(1, 1, 3, 3).float().to(images.device)\n\n    edges_x = F.conv2d(images, sobel_x, padding=1)\n    edges_y = F.conv2d(images, sobel_y, padding=1)\n    edge_magnitude = torch.sqrt(edges_x**2 + edges_y**2)\n\n    # Normalize and invert edge magnitude to prioritize smooth regions\n    suitability = 1 - (edge_magnitude / edge_magnitude.max())\n    return suitability\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = 10  # Update based on your dataset\nmodel = StegoLocationNet(num_classes=num_classes)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Get the number of classes from your dataset\nnum_classes = len(cifar10_data.classes) + len(fashionmnist_data.classes) + len(stego_data.classes)\n\n# Load the EfficientNet model\n# Get the number of classes from your dataset\nnum_classes = len(cifar10_data.classes) + len(fashionmnist_data.classes) + len(stego_data.classes)\n\n# Create model\nmodel = StegoLocationNet(num_classes=num_classes)\n\n# Move model to the appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add this helper function above the training loop\ndef generate_hiding_spots(images, threshold=0.8):\n    \"\"\"\n    Generate target masks indicating good hiding spots\n    This is a simple example using edge detection and local variance\n    \"\"\"\n    batch_size = images.size(0)\n    masks = torch.zeros((batch_size, 1, images.size(2), images.size(3))).to(images.device)\n    \n    for i in range(batch_size):\n        img = images[i].cpu().permute(1, 2, 0).numpy()\n        \n        # Convert to grayscale\n        gray = np.mean(img, axis=2)\n        \n        # Calculate local variance\n        local_var = ndimage.generic_filter(gray, np.var, size=3)\n        \n        # Normalize and threshold\n        local_var = (local_var - local_var.min()) / (local_var.max() - local_var.min())\n        masks[i, 0] = torch.from_numpy(local_var > threshold).float().to(images.device)\n    \n    return masks","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the function to generate target masks\ndef generate_hiding_spots(images, threshold=0.8):\n    \"\"\"\n    Generate target masks indicating good hiding spots.\n    This is a simple example using edge detection and local variance.\n    \"\"\"\n    batch_size = images.size(0)\n    masks = torch.zeros((batch_size, 1, images.size(2), images.size(3))).to(images.device)\n\n    # Example implementation: Fill the masks with zeros or apply a heuristic\n    for i in range(batch_size):\n        img = images[i].cpu().permute(1, 2, 0).numpy()\n        # Add your heuristic for detecting hiding spots here\n        # For example, based on edge detection, variance, or other methods\n        pass\n\n    return masks\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nnum_epochs = 2\nbatch_size = 64  # Define the batch size for DataLoader\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0.0  # Track the total loss for the epoch\n\n    for i, (images, _) in enumerate(train_loader):  # Process in batches\n        images = images.to(device)\n\n        # Generate target masks\n        target_masks = generate_hiding_spots(images)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        location_maps, _ = model(images)  # Unpack the tuple to get location_map\n\n        # Upsample location_maps to match target_masks\n        location_maps_upsampled = torch.nn.functional.interpolate(\n            location_maps, size=target_masks.shape[2:], mode='bilinear', align_corners=False\n        )\n\n        # Calculate loss\n        loss = criterion(location_maps_upsampled, target_masks)\n\n        # Backward pass\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()  # Accumulate loss for the epoch\n\n    # Log average loss for the epoch\n    avg_loss = epoch_loss / len(train_loader)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Location maps size: {location_maps.shape}\")\nprint(f\"Target masks size: {target_masks.shape}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0.0\n    with torch.no_grad():\n        for images, _ in test_loader:  # Ignore original labels\n            images = images.to(device)\n\n            # Generate target masks for testing\n            target_masks = generate_hiding_spots(images)\n\n            # Forward pass\n            location_maps, _ = model(images)\n\n            # Resize `location_maps` to match `target_masks` size\n            location_maps_resized = F.interpolate(\n                location_maps, size=target_masks.shape[2:], mode=\"bilinear\", align_corners=False\n            )\n\n            # Compute loss\n            loss = criterion(location_maps_resized, target_masks)\n\n            # Accumulate loss\n            test_loss += loss.item()\n\n    avg_test_loss = test_loss / len(test_loader)\n    print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n    return avg_test_loss\n\n# Perform evaluation\naverage_test_loss = evaluate_model(model, test_loader, criterion, device)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-12T11:58:51.830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the file path\nmodel_save_path = \"./model.pth\"\n\n# Save the model's state dictionary\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}